Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Agrawal1993,
author = {Agrawal, Divyakant and Abbadi, Amr El},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal, Abbadi - 1993 - Constrained Shared Locks for increasing Concurrency in Databases.pdf:pdf},
journal = {Journal of Computer and System Sciences},
keywords = {database},
pages = {53--63},
title = {{Constrained Shared Locks for increasing Concurrency in Databases}},
volume = {51},
year = {1993}
}
@article{Adya2000,
abstract = {Commercial databases support different isolation levels to allow programmers to trade off consistency for a potential gain in performance. The isolation levels are defined in the current ANSI standard, but the definitions are ambiguous and revised definitions proposed to correct the problem are too constrained since they allow only pessimistic (locking) implementations. This paper presents new specifications for the ANSI levels. Our specifications are portable; they apply not only to locking implementations, but also to opti-mistic and multi-version concurrency control schemes. Fur-thermore, unlike earlier definitions, our new specifications handle predicates in a correct and flexible manner at all levels.},
author = {Adya, Atul and Liskov, Barbara and {O 'neil}, Patrick},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adya, Liskov, O 'neil - 2000 - Generalized Isolation Level Definitions.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Data Engineering},
keywords = {database},
title = {{Generalized Isolation Level Definitions}},
year = {2000}
}
@inproceedings{Baker2011,
abstract = {Megastore is a storage system developed to meet the re-quirements of today's interactive online services. Megas-tore blends the scalability of a NoSQL datastore with the convenience of a traditional RDBMS in a novel way, and provides both strong consistency guarantees and high avail-ability. We provide fully serializable ACID semantics within fine-grained partitions of data. This partitioning allows us to synchronously replicate each write across a wide area net-work with reasonable latency and support seamless failover between datacenters. This paper describes Megastore's se-mantics and replication algorithm. It also describes our ex-perience supporting a wide range of Google production ser-vices built with Megastore.},
author = {Baker, Jason and Bond, Chris and Corbett, James C and Furman, Jj and Khorlin, Andrey and Larson, James and Eon, Jean-Michel and Li, Yawei and Lloyd, Alexander and Yushprakh, Vadim},
booktitle = {Proceedings of the Conference on Innovative Data system Research (CIDR)},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker et al. - Unknown - Megastore Providing Scalable, Highly Available Storage for Interactive Services.pdf:pdf},
keywords = {Bigtable,Design,Distributed databases,Distributed transactions,H24 [Database Management],Paxos,Performance,Reliability Keywords Large databases,Systems—concurrency,database,distrib-uted databases General Terms Algorithms},
pages = {223--234},
title = {{Megastore: Providing Scalable, Highly Available Storage for Interactive Services}},
url = {http://www.cidrdb.org/cidr2011/Papers/CIDR11{\_}Paper32.pdf{\%}7D},
year = {2011}
}
@inproceedings{Das2010,
abstract = {Cloud computing has emerged as a preferred platform for deploy-ing scalable web-applications. With the growing scale of these ap-plications and the data associated with them, scalable data man-agement systems form a crucial part of the cloud infrastructure. Key-Value stores – such as Bigtable, PNUTS, Dynamo, and their open source analogues– have been the preferred data stores for ap-plications in the cloud. In these systems, data is represented as Key-Value pairs, and atomic access is provided only at the granularity of single keys. While these properties work well for current applica-tions, they are insufficient for the next generation web applications – such as online gaming, social networks, collaborative editing, and many more – which emphasize collaboration. Since collaboration by definition requires consistent access to groups of keys, scalable and consistent multi key access is critical for such applications. We propose the Key Group abstraction that defines a relationship be-tween a group of keys and is the granule for on-demand transac-tional access. This abstraction allows the Key Grouping protocol to collocate control for the keys in the group to allow efficient access to the group of keys. Using the Key Grouping protocol, we design and implement G-Store which uses a key-value store as an underly-ing substrate to provide efficient, scalable, and transactional multi key access. Our implementation using a standard key-value store and experiments using a cluster of commodity machines show that G-Store preserves the desired properties of key-value stores, while providing multi key access functionality at a very low overhead.},
address = {New York, New York, USA},
author = {Das, Sudipto and Agrawal, Divyakant and {El Abbadi}, Amr},
booktitle = {Proceedings of the 1st ACM symposium on Cloud computing - SoCC '10},
doi = {10.1145/1807128.1807157},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Agrawal, Abbadi - Unknown - G-Store A Scalable Data Store for Transactional Multi key Access in the Cloud.pdf:pdf},
isbn = {9781450300360},
keywords = {Consistency,Design,H24 [Database Management],Key-Value stores,Multi key access,Performance Keywords Cloud computing,Sys-tems—Concurrency,Systems and Soft-ware—Distributed systems,Transaction processing General Terms Algorithms,database},
pages = {163},
publisher = {ACM Press},
title = {{G-Store: A Scalable Data Store for Transactional Multi key Access in the Cloud Sudipto}},
url = {http://portal.acm.org/citation.cfm?doid=1807128.1807157},
year = {2010}
}
@article{Cooper2008,
abstract = {We describe PNUTS, a massively parallel and geographi-cally distributed database system for Yahoo!'s web applica-tions. PNUTS provides data storage organized as hashed or ordered tables, low latency for large numbers of con-current requests including updates and queries, and novel per-record consistency guarantees. It is a hosted, centrally managed, and geographically distributed service, and uti-lizes automated load-balancing and failover to reduce oper-ational complexity. The first version of the system is cur-rently serving in production. We describe the motivation for PNUTS and the design and implementation of its table storage and replication layers, and then present experimen-tal results.},
author = {Cooper, Brian F and Ramakrishnan, Raghu and Srivastava, Utkarsh and Silberstein, Adam and Bohannon, Philip and Jacobsen, Hans-Arno and Puz, Nick and Weaver, Daniel and Yerneni, Ramana},
doi = {10.14778/1454159.1454167},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cooper et al. - Unknown - PNUTS Yahoo!'s Hosted Data Serving Platform.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
keywords = {database},
month = {aug},
number = {2},
pages = {1277--1288},
title = {{PNUTS: Yahoo!'s Hosted Data Serving Platform Brian}},
url = {http://dl.acm.org/citation.cfm?doid=1454159.1454167},
volume = {1},
year = {2008}
}
@inproceedings{Elmore2011,
abstract = {Multitenant data infrastructures for large cloud platforms hosting hundreds of thousands of applications face the challenge of serv-ing applications characterized by small data footprint and unpre-dictable load patterns. When such a platform is built on an elas-tic pay-per-use infrastructure, an added challenge is to minimize the system's operating cost while guaranteeing the tenants' service level agreements (SLA). Elastic load balancing is therefore an im-portant feature to enable scale-up during high load while scaling down when the load is low. Live migration, a technique to migrate tenants with minimal service interruption and no downtime, is crit-ical to allow lightweight elastic scaling. We focus on the prob-lem of live migration in the database layer. We propose Zephyr, a technique to efficiently migrate a live database in a shared noth-ing transactional database architecture. Zephyr uses phases of on-demand pull and asynchronous push of data, requires minimal syn-chronization, results no service unavailability and few or no aborted transactions, minimizes the data transfer overhead, provides ACID guarantees during migration, and ensures correctness in the pres-ence of failures. We outline a prototype implementation using an open source relational database engine and an present a thorough evaluation using various transactional workloads. Zephyr's effi-ciency is evident from the few tens of failed operations, 10-20{\%} change in average transaction latency, minimal messaging, and no overhead during normal operation when migrating a live database.},
address = {New York, New York, USA},
author = {Elmore, Aaron J and Das, Sudipto and Agrawal, Divyakant and {El Abbadi}, Amr},
booktitle = {Proceedings of the 2011 international conference on Management of data - SIGMOD '11},
doi = {10.1145/1989323.1989356},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elmore et al. - Unknown - Zephyr Live Migration in Shared Nothing Databases for Elastic Cloud Platforms.pdf:pdf},
isbn = {9781450306614},
keywords = {Cloud,Elasticity,Live migration,Multitenancy,Shared nothing database architectures,database},
pages = {301},
publisher = {ACM Press},
title = {{Zephyr: live migration in shared nothing databases for elastic cloud platforms}},
url = {http://portal.acm.org/citation.cfm?doid=1989323.1989356},
year = {2011}
}
@book{Bernstein1987,
author = {Bernstein, Philip A. and Hadzilacos, Vassco and Goodman, Nathan},
isbn = {0-201-10715-5},
keywords = {database},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
title = {{Concurrency Control and Recovery in Database Systems}},
year = {1987}
}
@article{Berenson1995,
abstract = {ANSI SQL-92 [MS, ANSI] defines Isolation Levels in terms of phenomena: Dirty Reads, Non-Re-peatable Reads, and Phantoms. This paper shows that these phenomena and the ANSI SQL definitions fail to characterize several popular isolation levels, including the standard locking implementations of the levels. Investigating the ambiguities of the phenomena leads to clearer definitions; in addition new phenomena that better characterize isolation types are introduced. An important multiversion isolation type, Snapshot Isolation, is defined.},
author = {Berenson, Hal and Bernstein, Phil and Gray, Jim and Melton, Jim and {O '}, Elizabeth and Umass, Neil and Boston, / and {O '}, Patrick},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berenson et al. - 1995 - A Critique of ANSI SQL Isolation Levels.pdf:pdf},
keywords = {database},
pages = {1--10},
title = {{A Critique of ANSI SQL Isolation Levels}},
year = {1995}
}
@article{Hellerstein2007,
abstract = {Database Management Systems (DBMSs) are a ubiquitous and critical component of modern computing, and the result of decades of research and development in both academia and industry. Historically, DBMSs were among the earliest multi-user server systems to be developed, and thus pioneered many systems design techniques for scalability and relia-bility now in use in many other contexts. While many of the algorithms and abstractions used by a DBMS are textbook material, there has been relatively sparse coverage in the literature of the systems design issues that make a DBMS work. This paper presents an architectural dis-cussion of DBMS design principles, including process models, parallel architecture, storage system design, transaction system implementa-tion, query processor and optimizer architectures, and typical shared components and utilities. Successful commercial and open-source sys-tems are used as points of reference, particularly when multiple alter-native designs have been adopted by different groups.},
author = {Hellerstein, Joseph M. and Stonebraker, Michael and Hamilton, James},
doi = {10.1561/1900000002},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hellerstein, Stonebraker, Hamilton - 2007 - Architecture of a Database System.pdf:pdf},
isbn = {9781601980786},
issn = {1931-7883},
journal = {Foundations and Trends{\textregistered} in Databases},
keywords = {database},
number = {2},
pages = {141--259},
pmid = {11490134},
title = {{Architecture of a Database System}},
url = {http://www.nowpublishers.com/article/Details/DBS-002},
volume = {1},
year = {2007}
}
@article{Larson2011,
abstract = {A database system optimized for in-memory storage can support much higher transaction rates than current systems. However, standard concurrency control methods used today do not scale to the high transaction rates achievable by such systems. In this pa-per we introduce two efficient concurrency control methods spe-cifically designed for main-memory databases. Both use multiver-sioning to isolate read-only transactions from updates but differ in how atomicity is ensured: one is optimistic and one is pessimistic. To avoid expensive context switching, transactions never block during normal processing but they may have to wait before com-mit to ensure correct serialization ordering. We also implemented a main-memory optimized version of single-version locking. Ex-perimental results show that while single-version locking works well when transactions are short and contention is low perfor-mance degrades under more demanding conditions. The multiver-sion schemes have higher overhead but are much less sensitive to hotspots and the presence of long-running transactions.},
author = {Larson, Per-{\AA}ke and Blanas, Spyros and Diaconu, Cristian and Freedman, Craig and Patel, Jignesh M and Zwilling, Mike},
doi = {10.14778/2095686.2095689},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larson et al. - 2012 - High-Performance Concurrency Control Mechanisms for Main-Memory Databases.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
keywords = {database},
month = {dec},
number = {4},
pages = {298--309},
title = {{High-performance concurrency control mechanisms for main-memory databases}},
url = {http://dl.acm.org/citation.cfm?doid=2095686.2095689},
volume = {5},
year = {2011}
}
@article{Kung1981,
abstract = {Most current approaches to concurrency control in database systems rely on locking of data objects as a control mechanism. In this paper, two families of nonlocking concurrency controls are presented. The methods used are " optimistic " in the sense that they rely mainly on transaction backup as a control mechanism, " hoping " that conflicts between transactions will not occur. Applications for which these methods should be more efficient than locking are discussed.},
author = {Kung, H T},
doi = {10.1145/319566.319567},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kung, Robinson - Unknown - On Optimistic Methods for Concurrency Control.pdf:pdf},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
keywords = {432,433,and Phrases,concurrency controls,database,databases,transaction processing CR Categories},
month = {jun},
number = {2},
pages = {213--226},
title = {{On optimistic methods for concurrency control}},
url = {http://portal.acm.org/citation.cfm?doid=319566.319567},
volume = {6},
year = {1981}
}
@article{Decandia2007,
abstract = {Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazon's core services use to provide an " always-on " experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use.},
author = {DeCandia, Giuseppe and Hastorun, Deniz and Jampani, Madan and Kakulapati, Gunavardhan and Lakshman, Avinash and Pilchin, Alex and Sivasubramanian, Swaminathan and Vosshall, Peter and Vogels, Werner},
doi = {10.1145/1323293.1294281},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Decandia et al. - Unknown - Dynamo Amazon's Highly Available Key-value Store.pdf:pdf},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {D42 [Operating Systems],D45 [Operating Systems],Design,General Terms Algorithms,Management,Measurement,Performance,Reliability,Storage Management,database},
month = {oct},
number = {6},
pages = {205},
title = {{Dynamo: Amazon's Highly Available Key-value Store}},
url = {http://portal.acm.org/citation.cfm?doid=1323293.1294281},
volume = {41},
year = {2007}
}
@article{DivyakantAgrawal2012,
author = {Agrawal, Divyakant and Das, Sudipto and Abbadi, Amr El},
doi = {10.2200/S00456ED1V01Y201211DTM032},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Divyakant Agrawal, Sudipto Das, Amr El Abbad - Unknown - Data Management in the Cloud Challenges and Opportunities.pdf:pdf},
issn = {2153-5418},
journal = {Synthesis Lectures on Data Management},
keywords = {database},
month = {dec},
number = {6},
pages = {1--138},
title = {{Data Management in the Cloud: Challenges and Opportunities}},
url = {http://www.morganclaypool.com/doi/abs/10.2200/S00456ED1V01Y201211DTM032},
volume = {4},
year = {2012}
}
@article{Das2011,
abstract = {Database systems serving cloud platforms must serve large num-bers of applications (or tenants). In addition to managing tenants with small data footprints, different schemas, and variable load pat-terns, such multitenant data platforms must minimize their oper-ating costs by efficient resource sharing. When deployed over a pay-per-use infrastructure, elastic scaling and load balancing, en-abled by low cost live migration of tenant databases, is critical to tolerate load variations while minimizing operating cost. How-ever, existing databases—relational databases and Key-Value stores alike—lack low cost live migration techniques, thus resulting in heavy performance impact during elastic scaling. We present Al-batross, a technique for live migration in a multitenant database serving OLTP style workloads where the persistent database im-age is stored in a network attached storage. Albatross migrates the database cache and the state of active transactions to ensure min-imal impact on transaction execution while allowing transactions active during migration to continue execution. It also guarantees serializability while ensuring correctness during failures. Our eval-uation using two OLTP benchmarks shows that Albatross can mi-grate a live tenant database with no aborted transactions, negligible impact on transaction latency and throughput both during and after migration, and an unavailability window as low as 300 ms.},
author = {Das, Sudipto and Nishimura, Shoji and Agrawal, Divyakant and {El Abbadi}, Amr},
doi = {10.14778/2002974.2002977},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das et al. - Unknown - Albatross Lightweight Elasticity in Shared Storage Databases for the Cloud using Live Data Migration.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
keywords = {Cloud computing,Database migration,Elastic Data Management,Fault-tolerance,Scalability,database},
month = {may},
number = {8},
pages = {494--505},
title = {{Albatross: Lightweight Elasticity in Shared Storage Databases for the Cloud Using Live Data Migration}},
url = {http://dl.acm.org/citation.cfm?doid=2002974.2002977},
volume = {4},
year = {2011}
}
@article{Chang2008,
abstract = {Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Fi-nance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the sim-ple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we de-scribe the design and implementation of Bigtable.},
author = {Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, Wilson C and Wallach, Deborah A and Burrows, Mike and Chandra, Tushar and Fikes, Andrew and Gruber, Robert E},
doi = {10.1145/1365815.1365816},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - Unknown - Bigtable A Distributed Storage System for Structured Data.pdf:pdf},
issn = {07342071},
journal = {ACM Transactions on Computer Systems},
keywords = {database},
month = {jun},
number = {2},
pages = {1--26},
title = {{Bigtable: A Distributed Storage System for Structured Data}},
url = {http://portal.acm.org/citation.cfm?doid=1365815.1365816},
volume = {26},
year = {2008}
}
@article{Gray2006,
abstract = {The distributed transaction commit problem requires reaching agreement on whether a transaction is committed or aborted. The classic Two-Phase Commit protocol blocks if the coordinator fails. Fault-tolerant consensus algorithms also reach agreement, but do not block whenever any majority of the processes are working. The Paxos Commit algorithm runs a Paxos consensus algorithm on the commit/abort decision of each participant to obtain a transaction commit protocol that uses 2F + 1 coordinators and makes progress if at least F + 1 of them are working properly. Paxos Commit has the same stable-storage write delay, and can be implemented to have the same message delay in the fault-free case as Two-Phase Commit, but it uses more messages. The classic Two-Phase Commit algorithm is obtained as the special F = 0 case of the Paxos Commit algorithm.},
author = {Gray, Jim and Lamport, Leslie},
doi = {10.1145/1132863.1132867},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gray, Lamport - 2006 - Consensus on Transaction Commit.pdf:pdf},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
keywords = {Algorithms,Categories and Subject Descriptors,Consensus,D41 [Operating Systems],D45 [Operating Systems],D47 [Operating Systems],Paxos,Process Management—Con-currency,Reliability Additional Key Words and Phrases,Reliability—Fault-tolerance,database,two-phase commit},
month = {mar},
number = {1},
pages = {133--160},
title = {{Consensus on transaction commit}},
url = {http://portal.acm.org/citation.cfm?doid=1132863.1132867},
volume = {31},
year = {2006}
}
@article{Das2013,
abstract = {A database management system (DBMS) serving a cloud platform must handle large numbers of application databases (or tenants) that are characterized by diverse schemas, varying footprints, and unpredictable load patterns. Scaling out using clusters of commodity servers and sharing resources among tenants (i.e., multi-tenancy) are important features of such systems. Moreover, when deployed on a pay-per-use infrastructure, minimizing the system's operating cost while ensuring good performance is also an important goal. Tradi-tional DBMSs were not designed for such scenarios and hence do not possess the mentioned features critical for DBMSs in the cloud. We present ElasTraS, which combines three design principles to build an elastically-scalable multitenant DBMS for transaction processing workloads. These design principles are gleaned from a careful analysis of the years of research in building scalable key-value stores and decades of research in high performance transaction processing systems. ElasTraS scales to thousands of tenants, effectively consolidates tenants with small footprints while scaling-out large tenants across multiple servers in a cluster. ElasTraS also supports low-latency multistep ACID transactions, is fault-tolerant, self-managing, and highly available to support mission critical applications. ElasTraS leverages Albatross, a low overhead on-demand live database migration technique, for elastic load balancing by adding more servers during high load and consolidating to fewer servers during usage troughs. This elastic scaling minimizes the operating cost and ensures good performance even in the presence of unpredictable changes to the workload. We elucidate the design principles, explain the architecture, describe a prototype implementation, present the detailed design and implementation of Albatross, and experimentally evaluate the implementation using a variety of transaction processing workloads. On a cluster of 20 commodity servers, our prototype serves thousands of tenants and serves more than 1 billion transactions per day while migrating tenant databases with minimal overhead to allow lightweight elastic scaling. Using a cluster of 30 commodity servers, ElasTraS can scale-out a terabyte TPC-C database serving an aggregate throughput of approximately one quarter of a million TPC-C transactions per minute.},
author = {Das, Sudipto and Agrawal, Divyakant and {El Abbadi}, Amr},
doi = {10.1145/2445583.2445588},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das et al. - 2013 - ElasTraS An Elastic, Scalable, and Self-Managing Transactional Database for the Cloud.pdf:pdf},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
keywords = {ACID,Algorithms,Categories and Subject Descriptors,Cloud computing,Design,H24 [Database Management],H34 [Information Storage and Retrieval],Performance Additional Key Words and Phrases,Systems—Concurrency,Transaction processing,database,elastic data management,fault-tolerance,scala-bility,transactions},
month = {apr},
number = {1},
pages = {1--45},
title = {{ElasTraS: An Elastic, Scalable, and Self-Managing Transactional Database for the Cloud}},
url = {http://dx.doi.org/10.1145/2445583.2445588 http://dl.acm.org/citation.cfm?doid=2445583.2445588},
volume = {38},
year = {2013}
}
@book{Weikum2002,
author = {Weikum, Gerhard and Vossen, Gottfried},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weikum, Vossen - Unknown - Transactional-Information-Systems.pdf:pdf},
isbn = {9780080519562},
keywords = {database},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Transactional-Information-Systems}},
year = {2002}
}
@article{Elhardt1984,
abstract = {Performance in database systems is strongly influenced by buffer management and transaction recovery methods. This paper presents the principles of the database cache, which replaces the traditional buffer. In comparison to buffer management, cache management is more carefully coordinated with transaction management, and integrates transaction recovery. High throughput of small-and medium-sized transactions is achieved by fast commit processing and low database traffic. Very fast handling of transaction failures and short restart time after system failure are guaranteed in such an environment. Very long retrieval and update transactions are also supported.},
author = {Elhardt, Klaus and Bayer, Rudolf},
doi = {10.1145/1994.1995},
file = {:home/griessbaum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elhardt, Bayer - 1984 - A Database Cache for High Performance and Fast Restart in Database Systems.pdf:pdf},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
keywords = {Algorithms,Buffer management,Categories and Subject Descriptors,H22 [Database Management],H24 [Database Management],Performance Additional Key Words and Phrases,Physical Design-recouery and restart,Systems--transaction processing General Terms,crash recovery,database,media failure,very long transactions},
month = {nov},
number = {4},
pages = {503--525},
title = {{A database cache for high performance and fast restart in database systems}},
url = {http://portal.acm.org/citation.cfm?doid=1994.1995},
volume = {9},
year = {1984}
}
